{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5709bcb",
   "metadata": {},
   "source": [
    "# Data clensing and SQL Data Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8464d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3ca40",
   "metadata": {},
   "source": [
    "Dataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327c0e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100005 entries, 0 to 100004\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   99998 non-null   float64\n",
      " 1   last_name            100003 non-null  object \n",
      " 2   first_name           100003 non-null  object \n",
      " 3   county               100003 non-null  object \n",
      " 4   district             100003 non-null  object \n",
      " 5   school               100003 non-null  object \n",
      " 6   primary_job          100003 non-null  object \n",
      " 7   fte                  100003 non-null  object \n",
      " 8   salary               99983 non-null   object \n",
      " 9   certificate          100003 non-null  object \n",
      " 10  subcategory          100003 non-null  object \n",
      " 11  teaching_route       100003 non-null  object \n",
      " 12  highly_qualified     100003 non-null  object \n",
      " 13  experience_district  100003 non-null  object \n",
      " 14  experience_nj        100003 non-null  object \n",
      " 15  experience_total     99983 non-null   object \n",
      "dtypes: float64(1), object(15)\n",
      "memory usage: 12.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/8qjdz4h56bb3smy6brz1xr6c0000gn/T/ipykernel_16154/2225393921.py:3: DtypeWarning: Columns (7,8,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv ('nj_teachers_salaries_pset4.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100005, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv ('nj_teachers_salaries_pset4.csv')\n",
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0fe64",
   "metadata": {},
   "source": [
    "## Droping All NaN Values Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf108bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100003, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how=\"all\", inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34185d",
   "metadata": {},
   "source": [
    "## Finding and Culling Bad Numerical Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5171405b-8861-4e0e-a7d6-b8a6d6b362cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 32789 \n",
      "\n",
      "First and last 10 incorrect rows and values:\n",
      "200 Gina\n",
      "1200 u\n",
      "10000 nan\n",
      "10001 nan\n",
      "10002 nan\n",
      "10003 nan\n",
      "10004 nan\n",
      "10005 nan\n",
      "10006 nan\n",
      "10007 nan\n",
      "65526 61880.0\n",
      "65527 51351.0\n",
      "65528 53164.0\n",
      "65529 58542.0\n",
      "65530 62340.0\n",
      "65531 111503.0\n",
      "65532 58435.0\n",
      "65533 92405.0\n",
      "65534 88598.0\n",
      "65535 55154.0\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 32767 \n",
      "\n",
      "First and last 10 float rows and values:\n",
      "32768 52534.0\n",
      "32769 107036.0\n",
      "32770 79556.0\n",
      "32771 86706.0\n",
      "32772 87428.0\n",
      "32773 58813.0\n",
      "32774 95583.0\n",
      "32775 73689.0\n",
      "32776 97965.0\n",
      "32777 67031.0\n",
      "65526 61880.0\n",
      "65527 51351.0\n",
      "65528 53164.0\n",
      "65529 58542.0\n",
      "65530 62340.0\n",
      "65531 111503.0\n",
      "65532 58435.0\n",
      "65533 92405.0\n",
      "65534 88598.0\n",
      "65535 55154.0\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the functions from the test that can be used for any column starting with finding\n",
    "# all the rows where an incorrect value is entered, inputing the name of the column as a string\n",
    "# and which dataframe should be used, and then outputting a list of all wrong rows\n",
    "def wrong_r(column, datfra):\n",
    "    wrong_rows = []\n",
    "\n",
    "    # Creating a for loop that will move through each entry in a column/field and check if it\n",
    "    # contains anything other than 0-9, and if it does it will add that column to a list.\n",
    "    for i in range(len(datfra)):\n",
    "\n",
    "        # Since several completely blank rows have already been removed, the loop experiences\n",
    "        # a range error when it runs into those rows, so first it will check if i matches one \n",
    "        # of the values from the dataframe and if it doesn't then that is a skipped row and\n",
    "        # the loop will iterate immediately to prevent the range error and move onto the \n",
    "        # the next populated row, while keeping the index of the for-loop synced with the \n",
    "        # index of the dataframe.\n",
    "        if i in datfra.index:\n",
    "            # Creating a variable that will store the value from a certain cell so it can be \n",
    "            # checked if it contains anything other than digits\n",
    "            value = datfra[column][i]\n",
    "\n",
    "            # Checking digits. If non digit detected then adding the index number to the list.\n",
    "            # Converting the value ot a string so that it can be correctly evaluated if the \n",
    "            # Column has already been converted to all ints or floats.\n",
    "            if str(value).isdigit() == False:\n",
    "                wrong_rows.append(i)\n",
    "\n",
    "        # Iterating if i doesn't match index i.e. row missing\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return wrong_rows\n",
    "\n",
    "# Printing the total quantity of incorrect entries and then printing the first 10 and\n",
    "# and last 10 row numbers and values as a visual sample. If the data has already been fixed\n",
    "# then it can also print the comparison. If no comparison then the same list should be listed\n",
    "# twice when calling the function.\n",
    "def print_wrong_sample (wrong_rows, new_wrong_rows, column, datfra, update):\n",
    "\n",
    "    # Assigning the length of both the original list and potential updated lists to display\n",
    "    wrong_rows_length = len(wrong_rows)\n",
    "    new_wrong_rows_length = len(new_wrong_rows)\n",
    "\n",
    "    # Creating a variable to create a print that will only print based on an earlier print function\n",
    "    difference = 0\n",
    "\n",
    "    print('Quantity of intially incorrect entries:', wrong_rows_length, '\\n')\n",
    "\n",
    "    if wrong_rows_length !=0:\n",
    "    \n",
    "        # Checking if the quantity was marked as updated and checking if their was a difference\n",
    "        # in the ammount of incorrect entries. If so, it will display the new quantity.\n",
    "        if (update == 'Y' or update == 'y') and wrong_rows != new_wrong_rows:\n",
    "            print('Current Quantity of incorrect entries:', new_wrong_rows_length, '\\n')\n",
    "            difference = 1\n",
    "            print('First and last 10 intially incorrect rows (with current values)')\n",
    "    \n",
    "        # If an update was requested but there wasn't a change in quantity then that will\n",
    "        # be displayed to the user.\n",
    "        elif update == 'Y' or update == 'y':\n",
    "            print('Quanity of incorrect entries has not changed \\n')\n",
    "            print('First and last 10 incorrect rows (with current values)')\n",
    "    \n",
    "        else: \n",
    "            print('First and last 10 incorrect rows and values:')\n",
    "            \n",
    "        # Now displaying the first 10 and last 10 \n",
    "        for item in wrong_rows[:10]+ wrong_rows[-10:]:\n",
    "            print(item, datfra[column][item])\n",
    "    \n",
    "        print('\\n')\n",
    "    \n",
    "        # Checking if previous check found a new quantity of incorrect entries, and then\n",
    "        # Printing the first and last 10 entries of update\n",
    "        if difference == 1:\n",
    "            print('Current first and last 10 incorrect rows and values:')\n",
    "            for item in new_wrong_rows[:10]+ new_wrong_rows[-10:]:\n",
    "                print(item, datfra[column][item])\n",
    "    \n",
    "            print('\\n')\n",
    "\n",
    "# Creating a function to detect which of the incorrect entries in the column are floats,\n",
    "# which will then be stored in a list which can be displayed. Additionally it will check\n",
    "# if any of the float entries are ints that miscelleniously had '.0' tacked on causing them \n",
    "# to be read as floats and simply need to have the float part trimmed.\n",
    "def float_r(column, datfra):\n",
    "    float_rows = []\n",
    "    non_zero_float = []\n",
    "    zero_float = []\n",
    "\n",
    "    # Creating loop to check each entry in the column to see if it contains a '.'\n",
    "    for i in range(len(datfra)):\n",
    "\n",
    "        # Following the same intial protocol of wrong_r and checking to make sure the indeces \n",
    "        # match\n",
    "        if i in datfra.index:\n",
    "            value = datfra[column][i]\n",
    "\n",
    "            # Checking if the value is actually a float by detecting if the string version\n",
    "            # of the value contains the character '.' is present but only once and if all\n",
    "            # other symbols are digits.\n",
    "            if '.' in str(value) and str(value).replace('.','',1).isdigit() == True:\n",
    "                float_rows.append(i)\n",
    "\n",
    "                # Separating out the part after the decimal place in order to detect if the \n",
    "                # the decimal portion of the value is only a single zero in the tenths place\n",
    "                # and then likely good data just entered as the wrong data type\n",
    "                decimal_part = str(value).split('.')[1]\n",
    "                if '.0' not in str(value) or len(decimal_part) >=2:\n",
    "                    # Saving the location of any entries that violate this check.\n",
    "                    non_zero_float.append(i)\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Creating an additional list of all the locations of just entries that seem to have correct\n",
    "    # values with the '.0' added in case it is desired that these be specifically imputed\n",
    "    zero_float = list(set(float_rows) - set(non_zero_float))\n",
    "\n",
    "    return float_rows, non_zero_float, zero_float\n",
    "    \n",
    "def print_float_sample (float_rows, new_float_rows, column, datfra, update):\n",
    "    float_rows_length = len(float_rows)\n",
    "    \n",
    "    # Assigning the length of both the original list and potential updated lists to display\n",
    "    new_float_rows_length = len(new_float_rows)\n",
    "\n",
    "    # Creating a variable to create a print that will only print based on an earlier print function\n",
    "    difference = 0\n",
    "\n",
    "    print('Quantity of intial float entries:', float_rows_length, '\\n')\n",
    "\n",
    "    if float_rows_length !=0:\n",
    "\n",
    "        # Checking if the quantity was marked as updated and checking if their was a difference\n",
    "        # in the ammount of float entries. If so, it will display the new quantity.\n",
    "        if (update == 'Y' or update == 'y') and float_rows != new_float_rows:\n",
    "            print('Current Quantity of float entries:', new_float_rows_length, '\\n')\n",
    "            difference = 1\n",
    "            print('First and last 10 intial float rows (with current values)')\n",
    "    \n",
    "        # If an update was requested but there wasn't a change in quantity then that will\n",
    "        # be displayed to the user.\n",
    "        elif update == 'Y' or update == 'y':\n",
    "            print('Quanity of float entries has not changed \\n')\n",
    "            print('First and last 10 float rows (with current values)')\n",
    "    \n",
    "        else: \n",
    "            print('First and last 10 float rows and values:')\n",
    "            \n",
    "        # Now displaying the first 10 and last 10 \n",
    "        for item in float_rows[:10]+ float_rows[-10:]:\n",
    "            print(item, datfra[column][item])\n",
    "    \n",
    "        print('\\n')\n",
    "    \n",
    "        # Checking if previous check found a new quantity of float entries, and then\n",
    "        # Printing the first and last 10 entries of update\n",
    "        if difference == 1:\n",
    "            print('Current first and last 10 float rows and values:')\n",
    "            for item in new_float_rows[:10]+ new_float_rows[-10:]:\n",
    "                print(item, datfra[column][item])\n",
    "    \n",
    "            print('\\n')\n",
    "\n",
    "def print_non_zero_float_sample (non_zero_float, new_non_zero_float, column, datfra, update):\n",
    "    non_zero_float_length = len(non_zero_float)\n",
    "    \n",
    "    # Assigning the length of both the original list and potential updated lists to display\n",
    "    new_non_zero_float_length = len(new_non_zero_float)\n",
    "\n",
    "    # Creating a variable to create a print that will only print based on an earlier print function\n",
    "    difference = 0\n",
    "\n",
    "    print('Quantity of intially non-zero float entries:', non_zero_float_length, '\\n')\n",
    "\n",
    "    if non_zero_float_length !=0:\n",
    "\n",
    "        # Checking if the quantity was marked as updated and checking if their was a difference\n",
    "        # in the ammount of non-zero float entries. If so, it will display the new quantity.\n",
    "        if (update == 'Y' or update == 'y') and non_zero_float != new_non_zero_float:\n",
    "            print('Current Quantity of non-zero float entries:', new_non_zero_float_length, '\\n')\n",
    "            difference = 1\n",
    "            print('First and last 10 intially non-zero float rows (with current values)')\n",
    "    \n",
    "        # If an update was requested but there wasn't a change in quantity then that will\n",
    "        # be displayed to the user.\n",
    "        elif update == 'Y' or update == 'y':\n",
    "            print('Quanity of non-zero float entries has not changed \\n')\n",
    "            print('First and last 10 non-zero float rows (with current values)')\n",
    "    \n",
    "        else: \n",
    "            print('First and last 10 non-zero float rows and values:')\n",
    "            \n",
    "        # Now displaying the first 10 and last 10 \n",
    "        for item in non_zero_float[:10]+ non_zero_float[-10:]:\n",
    "            print(item, datfra[column][item])\n",
    "    \n",
    "        print('\\n')\n",
    "    \n",
    "        # Checking if previous check found a new quantity of non-zero float entries, and then\n",
    "        # Printing the first and last 10 entries of update\n",
    "        if difference == 1:\n",
    "            print('Current first and last 10 non-zero float rows and values:')\n",
    "            for item in new_non_zero_float[:10]+ new_non_zero_float[-10:]:\n",
    "                print(item, datfra[column][item])\n",
    "    \n",
    "            print('\\n')\n",
    "\n",
    "salary_wrong_rows = wrong_r('salary', df)\n",
    "\n",
    "print_wrong_sample(salary_wrong_rows, salary_wrong_rows, 'salary', df, 'n')\n",
    "\n",
    "salary_float_rows, salary_non_zero_float, salary_zero_float = float_r('salary', df)\n",
    "\n",
    "print_float_sample(salary_float_rows, salary_float_rows, 'salary', df, 'n')\n",
    "\n",
    "print_non_zero_float_sample(salary_non_zero_float, salary_non_zero_float, 'salary', df, 'n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b389199-e49c-4bf1-8c04-7638cf18aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the entries that seem to be floats seem to just incorrectly contain an extra .0\n",
    "# It seems like it would be a mistake to delete 32767 entries just for that reason.\n",
    "# However I don't believe we were taught any protocols for imputing data nor do the instructions\n",
    "# mention anything other than deleting incorrect data. I will create a parallel datafile.\n",
    "df2 = df.copy()\n",
    "\n",
    "# Creating a function that will take every innocious zero-float value and trim off the \n",
    "# '.0' while \n",
    "def zero_float_to_intstring(float_rows, column, datfra):\n",
    "    for x in float_rows:\n",
    "        datfra.loc[x, column] = str(datfra[column][x]).replace('.0','',1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a358a568-59ef-4c8b-886f-e14988d2f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using function to trim of the .0's for salary field and \n",
    "# turning all the float values into useable int values\n",
    "zero_float_to_intstring(salary_float_rows, 'salary', df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3356b0f5-b2b2-42a8-9ca9-cb901e70b16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 32789 \n",
      "\n",
      "Current Quantity of incorrect entries: 22 \n",
      "\n",
      "First and last 10 intially incorrect rows (with current values)\n",
      "200 Gina\n",
      "1200 u\n",
      "10000 nan\n",
      "10001 nan\n",
      "10002 nan\n",
      "10003 nan\n",
      "10004 nan\n",
      "10005 nan\n",
      "10006 nan\n",
      "10007 nan\n",
      "65526 61880\n",
      "65527 51351\n",
      "65528 53164\n",
      "65529 58542\n",
      "65530 62340\n",
      "65531 111503\n",
      "65532 58435\n",
      "65533 92405\n",
      "65534 88598\n",
      "65535 55154\n",
      "\n",
      "\n",
      "Current first and last 10 incorrect rows and values:\n",
      "200 Gina\n",
      "1200 u\n",
      "10000 nan\n",
      "10001 nan\n",
      "10002 nan\n",
      "10003 nan\n",
      "10004 nan\n",
      "10005 nan\n",
      "10006 nan\n",
      "10007 nan\n",
      "10010 nan\n",
      "10011 nan\n",
      "10012 nan\n",
      "10013 nan\n",
      "10014 nan\n",
      "10015 nan\n",
      "10016 nan\n",
      "10017 nan\n",
      "10018 nan\n",
      "10019 nan\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 32767 \n",
      "\n",
      "Current Quantity of float entries: 0 \n",
      "\n",
      "First and last 10 intial float rows (with current values)\n",
      "32768 52534\n",
      "32769 107036\n",
      "32770 79556\n",
      "32771 86706\n",
      "32772 87428\n",
      "32773 58813\n",
      "32774 95583\n",
      "32775 73689\n",
      "32776 97965\n",
      "32777 67031\n",
      "65526 61880\n",
      "65527 51351\n",
      "65528 53164\n",
      "65529 58542\n",
      "65530 62340\n",
      "65531 111503\n",
      "65532 58435\n",
      "65533 92405\n",
      "65534 88598\n",
      "65535 55154\n",
      "\n",
      "\n",
      "Current first and last 10 float rows and values:\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking how fixing the float values affected our lists of incorrect entries\n",
    "new_salary_wrong_rows = wrong_r('salary', df2)\n",
    "\n",
    "print_wrong_sample(salary_wrong_rows, new_salary_wrong_rows, 'salary', df2, 'y')\n",
    "\n",
    "new_salary_float_rows, new_salary_non_zero_float, new_salary_zero_float = float_r('salary', df2)\n",
    "\n",
    "print_float_sample(salary_float_rows, new_salary_float_rows, 'salary', df2, 'y')\n",
    "\n",
    "print_non_zero_float_sample(salary_non_zero_float, new_salary_non_zero_float, 'salary', df2, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34ae810-2e6f-4796-972b-ff24044122dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100003, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032eab69-ce70-490b-9655-4d3b3f7100db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 32789 \n",
      "\n",
      "First and last 10 incorrect rows and values:\n",
      "91 t\n",
      "200 Gina\n",
      "20000 nan\n",
      "20001 nan\n",
      "20002 nan\n",
      "20003 nan\n",
      "20004 nan\n",
      "20005 nan\n",
      "20006 nan\n",
      "20007 nan\n",
      "65526 40.0\n",
      "65527 14.0\n",
      "65528 40.0\n",
      "65529 12.0\n",
      "65530 27.0\n",
      "65531 33.0\n",
      "65532 10.0\n",
      "65533 39.0\n",
      "65534 40.0\n",
      "65535 35.0\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 32767 \n",
      "\n",
      "First and last 10 float rows and values:\n",
      "32768 4.0\n",
      "32769 23.0\n",
      "32770 40.0\n",
      "32771 26.0\n",
      "32772 4.0\n",
      "32773 33.0\n",
      "32774 31.0\n",
      "32775 14.0\n",
      "32776 35.0\n",
      "32777 0.0\n",
      "65526 40.0\n",
      "65527 14.0\n",
      "65528 40.0\n",
      "65529 12.0\n",
      "65530 27.0\n",
      "65531 33.0\n",
      "65532 10.0\n",
      "65533 39.0\n",
      "65534 40.0\n",
      "65535 35.0\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now applying the same system to the experience_total column to see if there are similar\n",
    "# problems\n",
    "field = 'experience_total'\n",
    "\n",
    "total_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(total_wrong_rows, total_wrong_rows, field, df, 'n')\n",
    "\n",
    "total_float_rows, total_non_zero_float, total_zero_float = float_r(field, df)\n",
    "\n",
    "print_float_sample(total_float_rows, total_float_rows, field, df, 'n')\n",
    "\n",
    "print_non_zero_float_sample(total_non_zero_float, total_non_zero_float, field, df, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a48ba9-1a68-4397-9003-9c5f20f1042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our function to remove .0s from experience_total\n",
    "zero_float_to_intstring(total_float_rows, field, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8002e9-cbb5-48e4-ac40-ad7183a238b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 32789 \n",
      "\n",
      "Current Quantity of incorrect entries: 22 \n",
      "\n",
      "First and last 10 intially incorrect rows (with current values)\n",
      "91 t\n",
      "200 Gina\n",
      "20000 nan\n",
      "20001 nan\n",
      "20002 nan\n",
      "20003 nan\n",
      "20004 nan\n",
      "20005 nan\n",
      "20006 nan\n",
      "20007 nan\n",
      "65526 40\n",
      "65527 14\n",
      "65528 40\n",
      "65529 12\n",
      "65530 27\n",
      "65531 33\n",
      "65532 10\n",
      "65533 39\n",
      "65534 40\n",
      "65535 35\n",
      "\n",
      "\n",
      "Current first and last 10 incorrect rows and values:\n",
      "91 t\n",
      "200 Gina\n",
      "20000 nan\n",
      "20001 nan\n",
      "20002 nan\n",
      "20003 nan\n",
      "20004 nan\n",
      "20005 nan\n",
      "20006 nan\n",
      "20007 nan\n",
      "20010 nan\n",
      "20011 nan\n",
      "20012 nan\n",
      "20013 nan\n",
      "20014 nan\n",
      "20015 nan\n",
      "20016 nan\n",
      "20017 nan\n",
      "20018 nan\n",
      "20019 nan\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 32767 \n",
      "\n",
      "Current Quantity of float entries: 0 \n",
      "\n",
      "First and last 10 intial float rows (with current values)\n",
      "32768 4\n",
      "32769 23\n",
      "32770 40\n",
      "32771 26\n",
      "32772 4\n",
      "32773 33\n",
      "32774 31\n",
      "32775 14\n",
      "32776 35\n",
      "32777 0\n",
      "65526 40\n",
      "65527 14\n",
      "65528 40\n",
      "65529 12\n",
      "65530 27\n",
      "65531 33\n",
      "65532 10\n",
      "65533 39\n",
      "65534 40\n",
      "65535 35\n",
      "\n",
      "\n",
      "Current first and last 10 float rows and values:\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking how fixing the float values affected our lists of incorrect entries\n",
    "new_total_wrong_rows = wrong_r(field, df2)\n",
    "\n",
    "print_wrong_sample(total_wrong_rows, new_total_wrong_rows, field, df2, 'y')\n",
    "\n",
    "new_total_float_rows, new_total_non_zero_float, new_total_zero_float = float_r(field, df2)\n",
    "\n",
    "print_float_sample(total_float_rows, new_total_float_rows, field, df2, 'y')\n",
    "\n",
    "print_non_zero_float_sample(total_non_zero_float, new_total_non_zero_float, field, df2, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad389c75-a2bd-4ee7-b4de-f8c039072e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 100001 \n",
      "\n",
      "First and last 10 incorrect rows and values:\n",
      "0 9.0\n",
      "1 13.0\n",
      "2 7.0\n",
      "3 26.0\n",
      "4 5.0\n",
      "5 20.0\n",
      "6 39.0\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 15.0\n",
      "99993 5.0\n",
      "99994 34.0\n",
      "99995 8.0\n",
      "99996 36.0\n",
      "99997 12.0\n",
      "99998 10.0\n",
      "99999 15.0\n",
      "100000 39.0\n",
      "100001 17.0\n",
      "100002 11.0\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 100000 \n",
      "\n",
      "First and last 10 float rows and values:\n",
      "0 9.0\n",
      "1 13.0\n",
      "2 7.0\n",
      "3 26.0\n",
      "4 5.0\n",
      "5 20.0\n",
      "6 39.0\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 15.0\n",
      "99993 5.0\n",
      "99994 34.0\n",
      "99995 8.0\n",
      "99996 36.0\n",
      "99997 12.0\n",
      "99998 10.0\n",
      "99999 15.0\n",
      "100000 39.0\n",
      "100001 17.0\n",
      "100002 11.0\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now applying the same system to the experience_nj column to see if there are similar\n",
    "# problems\n",
    "field = 'experience_nj'\n",
    "\n",
    "nj_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(nj_wrong_rows, nj_wrong_rows, field, df, 'n')\n",
    "\n",
    "nj_float_rows, nj_non_zero_float, nj_zero_float = float_r(field, df)\n",
    "\n",
    "print_float_sample(nj_float_rows, nj_float_rows, field, df, 'n')\n",
    "\n",
    "print_non_zero_float_sample(nj_non_zero_float, nj_non_zero_float, field, df, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a075942f-d144-4007-814d-6eb13923e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our function to remove .0s from experience_nj\n",
    "zero_float_to_intstring(nj_float_rows, field, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b16edb77-1458-48c5-ad56-3ed40b96feda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 100001 \n",
      "\n",
      "Current Quantity of incorrect entries: 1 \n",
      "\n",
      "First and last 10 intially incorrect rows (with current values)\n",
      "0 9\n",
      "1 13\n",
      "2 7\n",
      "3 26\n",
      "4 5\n",
      "5 20\n",
      "6 39\n",
      "7 1\n",
      "8 1\n",
      "9 15\n",
      "99993 5\n",
      "99994 34\n",
      "99995 8\n",
      "99996 36\n",
      "99997 12\n",
      "99998 10\n",
      "99999 15\n",
      "100000 39\n",
      "100001 17\n",
      "100002 11\n",
      "\n",
      "\n",
      "Current first and last 10 incorrect rows and values:\n",
      "200 Gina\n",
      "200 Gina\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 100000 \n",
      "\n",
      "Current Quantity of float entries: 0 \n",
      "\n",
      "First and last 10 intial float rows (with current values)\n",
      "0 9\n",
      "1 13\n",
      "2 7\n",
      "3 26\n",
      "4 5\n",
      "5 20\n",
      "6 39\n",
      "7 1\n",
      "8 1\n",
      "9 15\n",
      "99993 5\n",
      "99994 34\n",
      "99995 8\n",
      "99996 36\n",
      "99997 12\n",
      "99998 10\n",
      "99999 15\n",
      "100000 39\n",
      "100001 17\n",
      "100002 11\n",
      "\n",
      "\n",
      "Current first and last 10 float rows and values:\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking how fixing the float values affected our lists of incorrect entries\n",
    "new_nj_wrong_rows = wrong_r(field, df2)\n",
    "\n",
    "print_wrong_sample(nj_wrong_rows, new_nj_wrong_rows, field, df2, 'y')\n",
    "\n",
    "new_nj_float_rows, new_nj_non_zero_float, new_nj_zero_float = float_r(field, df2)\n",
    "\n",
    "print_float_sample(nj_float_rows, new_nj_float_rows, field, df2, 'y')\n",
    "\n",
    "print_non_zero_float_sample(nj_non_zero_float, new_nj_non_zero_float, field, df2, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33e6a1e5-94e5-4835-aaca-0b498a22ca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 65535 \n",
      "\n",
      "First and last 10 incorrect rows and values:\n",
      "0 9.0\n",
      "1 13.0\n",
      "2 7.0\n",
      "3 26.0\n",
      "4 5.0\n",
      "5 1.0\n",
      "6 39.0\n",
      "7 1.0\n",
      "8 22.0\n",
      "9 15.0\n",
      "65527 7.0\n",
      "65528 37.0\n",
      "65529 11.0\n",
      "65530 18.0\n",
      "65531 4.0\n",
      "65532 10.0\n",
      "65533 7.0\n",
      "65534 11.0\n",
      "65535 21.0\n",
      "86035 j\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 65533 \n",
      "\n",
      "First and last 10 float rows and values:\n",
      "0 9.0\n",
      "1 13.0\n",
      "2 7.0\n",
      "3 26.0\n",
      "4 5.0\n",
      "5 1.0\n",
      "6 39.0\n",
      "7 1.0\n",
      "8 22.0\n",
      "9 15.0\n",
      "65526 3.0\n",
      "65527 7.0\n",
      "65528 37.0\n",
      "65529 11.0\n",
      "65530 18.0\n",
      "65531 4.0\n",
      "65532 10.0\n",
      "65533 7.0\n",
      "65534 11.0\n",
      "65535 21.0\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now applying the same system to the experience_district column to see if there are similar\n",
    "# problems\n",
    "field = 'experience_district'\n",
    "\n",
    "district_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(district_wrong_rows, district_wrong_rows, field, df, 'n')\n",
    "\n",
    "district_float_rows, district_non_zero_float, district_zero_float = float_r(field, df)\n",
    "\n",
    "print_float_sample(district_float_rows, district_float_rows, field, df, 'n')\n",
    "\n",
    "print_non_zero_float_sample(district_non_zero_float, district_non_zero_float, field, df, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "244c1db2-4713-44e3-90ed-af7398944292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our function to remove .0s from experience_district\n",
    "zero_float_to_intstring(district_float_rows, field, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cedcc567-5c12-49c0-8feb-a632f4c8960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 65535 \n",
      "\n",
      "Current Quantity of incorrect entries: 2 \n",
      "\n",
      "First and last 10 intially incorrect rows (with current values)\n",
      "0 9\n",
      "1 13\n",
      "2 7\n",
      "3 26\n",
      "4 5\n",
      "5 1\n",
      "6 39\n",
      "7 1\n",
      "8 22\n",
      "9 15\n",
      "65527 7\n",
      "65528 37\n",
      "65529 11\n",
      "65530 18\n",
      "65531 4\n",
      "65532 10\n",
      "65533 7\n",
      "65534 11\n",
      "65535 21\n",
      "86035 j\n",
      "\n",
      "\n",
      "Current first and last 10 incorrect rows and values:\n",
      "200 Gina\n",
      "86035 j\n",
      "200 Gina\n",
      "86035 j\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 65533 \n",
      "\n",
      "Current Quantity of float entries: 0 \n",
      "\n",
      "First and last 10 intial float rows (with current values)\n",
      "0 9\n",
      "1 13\n",
      "2 7\n",
      "3 26\n",
      "4 5\n",
      "5 1\n",
      "6 39\n",
      "7 1\n",
      "8 22\n",
      "9 15\n",
      "65526 3\n",
      "65527 7\n",
      "65528 37\n",
      "65529 11\n",
      "65530 18\n",
      "65531 4\n",
      "65532 10\n",
      "65533 7\n",
      "65534 11\n",
      "65535 21\n",
      "\n",
      "\n",
      "Current first and last 10 float rows and values:\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking how fixing the float values affected our lists of incorrect entries\n",
    "new_district_wrong_rows = wrong_r(field, df2)\n",
    "\n",
    "print_wrong_sample(district_wrong_rows, new_district_wrong_rows, field, df2, 'y')\n",
    "\n",
    "new_district_float_rows, new_district_non_zero_float, new_district_zero_float = float_r(field, df2)\n",
    "\n",
    "print_float_sample(district_float_rows, new_district_float_rows, field, df2, 'y')\n",
    "\n",
    "print_non_zero_float_sample(district_non_zero_float, new_district_non_zero_float, field, df2, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cef93c0-6fa9-44a0-9df3-55fbdb593a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since experience_state would only have two entries if this protocol is not followe,\n",
    "# I am going to assume that this is the correct protocol and will set df2 back to df \n",
    "# for the rest of the assignment.\n",
    "df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b317cd-90f4-467b-bae9-b9885a580c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_r_dec(column, datfra):\n",
    "    wrong_rows = []\n",
    "\n",
    "    # Creating a for loop that will move through each entry in a column/field and check if it\n",
    "    # contains anything that can't be reassigned to a float, and if it does it will add that\n",
    "    # column to a list.\n",
    "    for i in range(len(datfra)):\n",
    "\n",
    "        # Since several completely blank rows have already been removed, the loop experiences\n",
    "        # a range error when it runs into those rows, so first it will check if i matches one \n",
    "        # of the values from the dataframe and if it doesn't then that is a skipped row and\n",
    "        # the loop will iterate immediately to prevent the range error and move onto the \n",
    "        # the next populated row, while keeping the index of the for-loop synced with the \n",
    "        # index of the dataframe.\n",
    "        if i in datfra.index:\n",
    "            # Creating a variable that will store the value from a certain cell so it can be \n",
    "            # checked if it contains anything that makes it not a float\n",
    "            value = datfra[column][i]\n",
    "            value_str = str(value)\n",
    "            \n",
    "            # I will use a try statement here instead of an if statement as the .isdigit()\n",
    "            # function won't be able to easily analyze whether the entry meets the specific \n",
    "            # parameters of being a float. Try statements let us see if a task fails, and if so\n",
    "            # we can do otherwise without creating an error. If it fails to convert value_float\n",
    "            # into a float from a string then we will save it as an incorrect entry.\n",
    "            try:\n",
    "                value_float = float(value_str)\n",
    "            except:\n",
    "                wrong_rows.append(i)\n",
    "                # We will add a continue just to make sure the code iterates correctly\n",
    "                continue\n",
    "\n",
    "        # Iterating if i doesn't match index i.e. row missing\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return wrong_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddfc3a33-410f-45e4-932c-a7ae3edf2eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 1 \n",
      "\n",
      "First and last 10 incorrect rows and values:\n",
      "200 Gina\n",
      "200 Gina\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding bad rows for fte.\n",
    "field = 'fte'\n",
    "\n",
    "fte_wrong_rows = wrong_r_dec(field, df)\n",
    "\n",
    "print_wrong_sample(fte_wrong_rows, fte_wrong_rows, field, df, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a6876a0-2681-4edb-aeba-9354838bac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all the incorrect fields of the int columns\n",
    "df[['salary', 'experience_district', 'experience_nj', 'experience_total']] = \\\n",
    "df[['salary', 'experience_district', 'experience_nj', 'experience_total']].replace\\\n",
    "('[^0-9]',np.nan,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eabc0f15-a7be-4a0b-b7b2-e98efac954b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary:\n",
      "Quantity of intially incorrect entries: 22 \n",
      "\n",
      "Quanity of incorrect entries has not changed \n",
      "\n",
      "First and last 10 incorrect rows (with current values)\n",
      "200 nan\n",
      "1200 nan\n",
      "10000 nan\n",
      "10001 nan\n",
      "10002 nan\n",
      "10003 nan\n",
      "10004 nan\n",
      "10005 nan\n",
      "10006 nan\n",
      "10007 nan\n",
      "10010 nan\n",
      "10011 nan\n",
      "10012 nan\n",
      "10013 nan\n",
      "10014 nan\n",
      "10015 nan\n",
      "10016 nan\n",
      "10017 nan\n",
      "10018 nan\n",
      "10019 nan\n",
      "\n",
      "\n",
      "Experience Total:\n",
      "Quantity of intially incorrect entries: 22 \n",
      "\n",
      "Quanity of incorrect entries has not changed \n",
      "\n",
      "First and last 10 incorrect rows (with current values)\n",
      "91 nan\n",
      "200 nan\n",
      "20000 nan\n",
      "20001 nan\n",
      "20002 nan\n",
      "20003 nan\n",
      "20004 nan\n",
      "20005 nan\n",
      "20006 nan\n",
      "20007 nan\n",
      "20010 nan\n",
      "20011 nan\n",
      "20012 nan\n",
      "20013 nan\n",
      "20014 nan\n",
      "20015 nan\n",
      "20016 nan\n",
      "20017 nan\n",
      "20018 nan\n",
      "20019 nan\n",
      "\n",
      "\n",
      "Experience NJ:\n",
      "Quantity of intially incorrect entries: 1 \n",
      "\n",
      "Quanity of incorrect entries has not changed \n",
      "\n",
      "First and last 10 incorrect rows (with current values)\n",
      "200 nan\n",
      "200 nan\n",
      "\n",
      "\n",
      "Experience District:\n",
      "Quantity of intially incorrect entries: 2 \n",
      "\n",
      "Quanity of incorrect entries has not changed \n",
      "\n",
      "First and last 10 incorrect rows (with current values)\n",
      "200 nan\n",
      "86035 nan\n",
      "200 nan\n",
      "86035 nan\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if all fields went to blank\n",
    "print('Salary:')\n",
    "blank_salary_wrong_rows = wrong_r('salary', df)\n",
    "\n",
    "print_wrong_sample(new_salary_wrong_rows, blank_salary_wrong_rows, 'salary', df, 'y')\n",
    "\n",
    "print('Experience Total:')\n",
    "\n",
    "field = 'experience_total'\n",
    "blank_total_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(new_total_wrong_rows, blank_total_wrong_rows, field, df, 'y')\n",
    "\n",
    "print('Experience NJ:')\n",
    "\n",
    "field = 'experience_nj'\n",
    "blank_nj_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(new_nj_wrong_rows, blank_nj_wrong_rows, field, df, 'y')\n",
    "\n",
    "print('Experience District:')\n",
    "\n",
    "field = 'experience_district'\n",
    "blank_district_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(new_district_wrong_rows, blank_district_wrong_rows, field, df, 'y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7ca4fc5-2972-41aa-9acc-8c82dc5b78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766a78fa-101b-4ad5-8819-d6d2d475dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that just allows the quantities to of errors to be checked and compared\n",
    "# If the rows were just removed then trying to access their values will cause an error\n",
    "def print_wrong_quant (wrong_rows, new_wrong_rows, column, datfra, update):\n",
    "\n",
    "    # Assigning the length of both the original list and potential updated lists to display\n",
    "    wrong_rows_length = len(wrong_rows)\n",
    "    new_wrong_rows_length = len(new_wrong_rows)\n",
    "\n",
    "    # Creating a variable to create a print that will only print based on an earlier print function\n",
    "    difference = 0\n",
    "\n",
    "    print('Quantity of intially incorrect entries:', wrong_rows_length, '\\n')\n",
    "\n",
    "    if wrong_rows_length !=0:\n",
    "    \n",
    "        # Checking if the quantity was marked as updated and checking if their was a difference\n",
    "        # in the ammount of incorrect entries. If so, it will display the new quantity.\n",
    "        if (update == 'Y' or update == 'y') and wrong_rows != new_wrong_rows:\n",
    "            print('Current Quantity of incorrect entries:', new_wrong_rows_length, '\\n')\n",
    "            difference = 1\n",
    "    \n",
    "        # If an update was requested but there wasn't a change in quantity then that will\n",
    "        # be displayed to the user.\n",
    "        elif update == 'Y' or update == 'y':\n",
    "            print('Quanity of incorrect entries has not changed \\n')\n",
    "    \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f68e42e8-48c6-4d43-a13b-1648317279ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fte:\n",
      "Quantity of intially incorrect entries: 1 \n",
      "\n",
      "Current Quantity of incorrect entries: 0 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('fte:')\n",
    "\n",
    "field = 'fte'\n",
    "\n",
    "new_fte_wrong_rows = wrong_r_dec(field, df)\n",
    "\n",
    "print_wrong_quant(fte_wrong_rows, new_fte_wrong_rows, field, df, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc7368c0-0490-454c-a91c-8bc516857cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All incorrect rows with decimal places have already been removed so an extra expression is\n",
    "# not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fed395b-6742-4463-97e7-a38cdc57ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary:\n",
      "Quantity of intially incorrect entries: 22 \n",
      "\n",
      "Current Quantity of incorrect entries: 0 \n",
      "\n",
      "\n",
      "\n",
      "Experience Total:\n",
      "Quantity of intially incorrect entries: 22 \n",
      "\n",
      "Current Quantity of incorrect entries: 0 \n",
      "\n",
      "\n",
      "\n",
      "Experience NJ:\n",
      "Quantity of intially incorrect entries: 1 \n",
      "\n",
      "Current Quantity of incorrect entries: 0 \n",
      "\n",
      "\n",
      "\n",
      "Experience District:\n",
      "Quantity of intially incorrect entries: 2 \n",
      "\n",
      "Current Quantity of incorrect entries: 0 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if all fields went to blank\n",
    "print('Salary:')\n",
    "clear_salary_wrong_rows = wrong_r('salary', df)\n",
    "\n",
    "print_wrong_quant(new_salary_wrong_rows, clear_salary_wrong_rows, 'salary', df, 'y')\n",
    "\n",
    "print('Experience Total:')\n",
    "\n",
    "field = 'experience_total'\n",
    "clear_total_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_quant(new_total_wrong_rows, clear_total_wrong_rows, field, df, 'y')\n",
    "\n",
    "print('Experience NJ:')\n",
    "\n",
    "field = 'experience_nj'\n",
    "clear_nj_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_quant(new_nj_wrong_rows, clear_nj_wrong_rows, field, df, 'y')\n",
    "\n",
    "print('Experience District:')\n",
    "\n",
    "field = 'experience_district'\n",
    "clear_district_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_quant(new_district_wrong_rows, clear_district_wrong_rows, field, df, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d551341-4be7-4aaf-8b03-dd28f70b0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the data type for all int columns\n",
    "df = df.copy()\n",
    "columns_to_convert = ['salary', 'experience_district', 'experience_nj', 'experience_total'] \n",
    "for col in columns_to_convert:\n",
    "    df[col] = pd.to_numeric(df[col], downcast ='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27d7c904-679d-4192-b31e-db8e2de6de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the data type for the float column, fte.\n",
    "df['fte'] = pd.to_numeric(df['fte'], downcast ='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a4cfb3d-e29e-49af-9e89-6debd14af202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99954 entries, 0 to 100004\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   99954 non-null  float64\n",
      " 1   last_name            99954 non-null  object \n",
      " 2   first_name           99954 non-null  object \n",
      " 3   county               99954 non-null  object \n",
      " 4   district             99954 non-null  object \n",
      " 5   school               99954 non-null  object \n",
      " 6   primary_job          99954 non-null  object \n",
      " 7   fte                  99954 non-null  float32\n",
      " 8   salary               99954 non-null  int32  \n",
      " 9   certificate          99954 non-null  object \n",
      " 10  subcategory          99954 non-null  object \n",
      " 11  teaching_route       99954 non-null  object \n",
      " 12  highly_qualified     99954 non-null  object \n",
      " 13  experience_district  99954 non-null  int8   \n",
      " 14  experience_nj        99954 non-null  int8   \n",
      " 15  experience_total     99954 non-null  int8   \n",
      "dtypes: float32(1), float64(1), int32(1), int8(3), object(10)\n",
      "memory usage: 12.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99954, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c041631-e259-45e3-93aa-76e8ca3a07f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 99903 \n",
      "\n",
      "First and last 10 incorrect rows and values:\n",
      "0 1.0\n",
      "1 2.0\n",
      "2 3.0\n",
      "3 4.0\n",
      "4 5.0\n",
      "5 6.0\n",
      "6 7.0\n",
      "7 8.0\n",
      "8 9.0\n",
      "9 10.0\n",
      "99944 99943.0\n",
      "99945 99944.0\n",
      "99946 99945.0\n",
      "99947 99946.0\n",
      "99948 99947.0\n",
      "99949 99948.0\n",
      "99950 99949.0\n",
      "99951 99950.0\n",
      "99952 99951.0\n",
      "99953 99952.0\n",
      "\n",
      "\n",
      "Quantity of intial float entries: 99903 \n",
      "\n",
      "First and last 10 float rows and values:\n",
      "0 1.0\n",
      "1 2.0\n",
      "2 3.0\n",
      "3 4.0\n",
      "4 5.0\n",
      "5 6.0\n",
      "6 7.0\n",
      "7 8.0\n",
      "8 9.0\n",
      "9 10.0\n",
      "99944 99943.0\n",
      "99945 99944.0\n",
      "99946 99945.0\n",
      "99947 99946.0\n",
      "99948 99947.0\n",
      "99949 99948.0\n",
      "99950 99949.0\n",
      "99951 99950.0\n",
      "99952 99951.0\n",
      "99953 99952.0\n",
      "\n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the id column, hopefully every column should have an error but also be part of the zero float list\n",
    "field = 'id'\n",
    "\n",
    "id_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(id_wrong_rows, id_wrong_rows, field, df, 'n')\n",
    "\n",
    "id_float_rows, id_non_zero_float, id_zero_float = float_r(field, df)\n",
    "\n",
    "print_float_sample(id_float_rows, id_float_rows, field, df, 'n')\n",
    "\n",
    "print_non_zero_float_sample(id_non_zero_float, id_non_zero_float, field, df, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8ffe935-27a5-4794-8381-411751e64f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99968.0, 99969.0, 99970.0, 99971.0, 99972.0, 99973.0, 99974.0, 99975.0, 99976.0, 99977.0, 99978.0, 99979.0, 99980.0, 99981.0, 99982.0, 99983.0, 99984.0, 99961.0, 99985.0, 86035.0, 99986.0, 99987.0, 99988.0, 99989.0, 99990.0, 99991.0, 1562.0, 99992.0, 99993.0, 99994.0, 99995.0, 99996.0, 99997.0, 99998.0, 99999.0, 100000.0, 100001.0, 100002.0, 100003.0, 1200.0, 200.0, 91.0, 99954.0, 99955.0, 99956.0, 46709.0, 99957.0, 99959.0, 99960.0, 99958.0, 99962.0, 99963.0, 99964.0, 99965.0, 99966.0, 99967.0]\n"
     ]
    }
   ],
   "source": [
    "all_id = df['id'].tolist()\n",
    "other_id = list(set(all_id)-set(id_wrong_rows))\n",
    "print(other_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b310a6d3-f9d3-4973-8527-ced40e354b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am not sure why these weren't returned by my program as well. Some \n",
    "# of them seem to have been deleted, but none of them are in the incorrect format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba9b5dc5-702e-4bb3-982f-d457e310c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = pd.to_numeric(df['id'], downcast ='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f75bef52-1ec6-4c43-aefe-7844efec6028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of intially incorrect entries: 0 \n",
      "\n",
      "Quantity of intial float entries: 0 \n",
      "\n",
      "Quantity of intially non-zero float entries: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "field = 'id'\n",
    "\n",
    "id_wrong_rows = wrong_r(field, df)\n",
    "\n",
    "print_wrong_sample(id_wrong_rows, id_wrong_rows, field, df, 'n')\n",
    "\n",
    "id_float_rows, id_non_zero_float, id_zero_float = float_r(field, df)\n",
    "\n",
    "print_float_sample(id_float_rows, id_float_rows, field, df, 'n')\n",
    "\n",
    "print_non_zero_float_sample(id_non_zero_float, id_non_zero_float, field, df, 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fcb477f-aacf-4cf2-bd84-db4703dd3f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99954 entries, 0 to 100004\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   99954 non-null  int32  \n",
      " 1   last_name            99954 non-null  object \n",
      " 2   first_name           99954 non-null  object \n",
      " 3   county               99954 non-null  object \n",
      " 4   district             99954 non-null  object \n",
      " 5   school               99954 non-null  object \n",
      " 6   primary_job          99954 non-null  object \n",
      " 7   fte                  99954 non-null  float32\n",
      " 8   salary               99954 non-null  int32  \n",
      " 9   certificate          99954 non-null  object \n",
      " 10  subcategory          99954 non-null  object \n",
      " 11  teaching_route       99954 non-null  object \n",
      " 12  highly_qualified     99954 non-null  object \n",
      " 13  experience_district  99954 non-null  int8   \n",
      " 14  experience_nj        99954 non-null  int8   \n",
      " 15  experience_total     99954 non-null  int8   \n",
      "dtypes: float32(1), int32(2), int8(3), object(10)\n",
      "memory usage: 11.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99954, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624f3e6",
   "metadata": {},
   "source": [
    "## Testing and Formatting String Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a36ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40000, 40001, 40002, 40003, 40004]\n",
      "40000  Christopher \n",
      "40119  Mallory \n"
     ]
    }
   ],
   "source": [
    "start_space = df.index[df['first_name'].str.startswith(' ')].tolist()\n",
    "print(start_space[:5])\n",
    "for item in start_space[:1]+ start_space[-1:]:\n",
    "    print(item, df['first_name'][item])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5d31e62-c5c3-4c98-a420-36f42c128b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40000, 40001, 40002, 40003, 40004]\n",
      "40000  Christopher \n",
      "40119  Mallory \n"
     ]
    }
   ],
   "source": [
    "end_space = df.index[df['first_name'].str.endswith(' ')].tolist()\n",
    "print(end_space[:5])\n",
    "for item in end_space[:1]+ end_space[-1:]:\n",
    "    print(item, df['first_name'][item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0e21809-3609-40a0-9178-481a5826024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_strip = ['last_name', 'first_name', 'county', 'district', 'school', 'primary_job', 'certificate', \\\n",
    "'subcategory', 'teaching_route', 'highly_qualified'] \n",
    "for col in columns_to_strip:\n",
    "    df[col]= df[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a72e768a-7256-4bc4-b774-90a4a95cbe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 Christopher\n",
      "40119 Mallory\n"
     ]
    }
   ],
   "source": [
    "for item in start_space[:1]+ start_space[-1:]:\n",
    "    print(item, df['first_name'][item])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f832694",
   "metadata": {},
   "source": [
    "## Finding Unwanted Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d0f6109-10c5-4f46-98ba-f9071cdb2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "specials = [',', \"'\", '/', '\"' '&', '(', ')', '-', ';', ':', '$', '.', '?', '!','[', ']', '%', \\\n",
    "            '^', '#']\n",
    "\n",
    "# Checking for special characters in stricter fields to get a sense of what they might look\n",
    "# like to guide what might be acceptable\n",
    "\n",
    "\n",
    "def check_simple_specs(column):\n",
    "    contains_speci = []\n",
    "    for speci in specials:\n",
    "        matches = df.index[df[column].str.contains(speci, regex=False)].tolist()\n",
    "        contains_speci.extend(matches)\n",
    "    print(contains_speci[:50])\n",
    "    for item in contains_speci[:1]+ contains_speci[-1:]:\n",
    "        print(item, df[column][item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f8858c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[60000, 60001, 60002, 60003, 60004, 60005, 60006, 60007, 60008, 60009, 60010, 60011, 60012, 60013, 60014, 60015, 60016, 60017, 60018, 60019]\n",
      "60000 Traditional éü 0.5556085214578451\n",
      "60019 Traditional éü 0.39726189913927534\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "check_simple_specs('first_name')\n",
    "\n",
    "check_simple_specs('last_name')\n",
    "\n",
    "check_simple_specs('teaching_route')\n",
    "\n",
    "check_simple_specs('subcategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2ee3ab4-4f36-42eb-a3d5-a440e28082cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No special characters detected. Assuming other special characters beyond those tested\n",
    "# are undesired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08c11dbc-3ef5-4cfe-959e-b4236d5a37e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 40, 124, 144, 157, 174, 277, 378, 430, 432, 446, 503, 608, 612, 690, 756, 800, 1002, 1017, 1071, 1073, 1077, 1122, 1171, 1251, 1259, 1275, 1297, 1518, 1572, 1689, 1709, 1779, 1794, 1824, 1840, 1915, 1966, 2003, 2095, 2106, 2113, 2141, 2238, 2263, 2307, 2326, 2446, 2492, 2668]\n",
      "22 Elementary Teacher In Secondary Setting Apa Only Subcategory Identifier S, H, Or V\n",
      "99904 Financial Literacy (math, Social Studies, Business:  Finance, Economics, Law, Comprehensive Business, Comprehensive Family And Consumer Sciences And G\n"
     ]
    }
   ],
   "source": [
    "# Testing on a column expected to contain more characters\n",
    "check_simple_specs('primary_job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "721c4c0a-e841-498e-9201-d648433c0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_name'] = df['first_name'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['last_name'] = df['last_name'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['teaching_route'] = df['teaching_route'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['subcategory'] = df['subcategory'].str.replace(r'[^A-Za-z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e277b5b-f270-419c-b10c-b3fc92317c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "check_simple_specs('first_name')\n",
    "\n",
    "check_simple_specs('last_name')\n",
    "\n",
    "check_simple_specs('teaching_route')\n",
    "\n",
    "check_simple_specs('subcategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c312c0e9-dc91-4da4-a1b1-ae34f803e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will extend the criteria to include allow for some apecial characters\n",
    "def check_extra_specs(column):\n",
    "    contains_speci = []\n",
    "    for speci in specials:\n",
    "        matches = df.index[df[column].str.contains(r\"[^0-9A-Za-z\\s,\\'\\/\\\"&\\(\\)\\-\\;\\:\\$\\.\\?\\!\\\\\\@\\[\\]%\\^#]\", regex=True)].tolist()\n",
    "        contains_speci.extend(matches)\n",
    "    print(contains_speci[:100])\n",
    "    for item in contains_speci[:5]+ contains_speci[-5:]:\n",
    "        print(item, df[column][item])\n",
    "    print('Total with issue:', len(contains_speci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f913d9a2-f03b-4a8f-a70a-b04edcc4321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3023, 3195, 3212, 3543, 3644, 4128, 4164, 4299, 4600, 4772, 4889, 4910, 5316, 5682, 5689, 5891, 6030, 6558, 6835, 6954, 7104, 8172, 8697, 9097, 9329, 9438, 9612, 9667, 9896, 10456, 10956, 13184, 13370, 13711, 13867, 14095, 14204, 14344, 15031, 15703, 15774, 15851, 16145, 16183, 16587, 16685, 16713, 16900, 16922, 17491, 17602, 18450, 18985, 19052, 19264, 19890, 19943, 19994, 20103, 20264, 20368, 20620, 21348, 21416, 21733, 21959, 22004, 22089, 22493, 22551, 22607, 22733, 23056, 23466, 23629, 24402, 24641, 25639, 25755, 25825, 26002, 26199, 26732, 26782, 26820, 26989, 27119, 28460, 29168, 29388, 29565, 29663, 29768, 29776, 30205, 30289, 30424, 30484, 30779, 30852]\n",
      "3023 Family & Consumer Sciences Ã¢â‚¬â€œ Apparel, Textiles And Interiors\n",
      "3195 Family & Consumer Sciences Ã¢â‚¬â€œ Apparel, Textiles And Interiors\n",
      "3212 Family & Consumer Sciences Ã¢â‚¬â€œ Apparel, Textiles And Interiors\n",
      "3543 Family & Consumer Sciences Ã¢â‚¬â€œ Apparel, Textiles And Interiors\n",
      "3644 Family & Consumer Sciences Ã¢â‚¬â€œ Apparel, Textiles And Interiors\n",
      "56053 Family & Consumer Sciences Ã¢â‚¬â€œ Foods/nutrition & Food Science\n",
      "56177 Family & Consumer Sciences Ã¢â‚¬â€œ Foods/nutrition & Food Science\n",
      "56204 Family & Consumer Sciences Ã¢â‚¬â€œ Foods/nutrition & Food Science\n",
      "56702 Family & Consumer Sciences Ã¢â‚¬â€œ Foods/nutrition & Food Science\n",
      "56870 Family & Consumer Sciences Ã¢â‚¬â€œ Foods/nutrition & Food Science\n",
      "Total with issue: 3726\n"
     ]
    }
   ],
   "source": [
    "check_extra_specs('primary_job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b06629a-6a93-43bf-870b-2f58d59dbc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Total with issue: 0\n",
      "[]\n",
      "Total with issue: 0\n",
      "[1849, 17420, 20127, 22149, 23155, 29145, 32398, 34020, 34960, 38514, 46363, 47684, 58519, 60547, 66889, 68157, 82805, 89493, 1849, 17420, 20127, 22149, 23155, 29145, 32398, 34020, 34960, 38514, 46363, 47684, 58519, 60547, 66889, 68157, 82805, 89493, 1849, 17420, 20127, 22149, 23155, 29145, 32398, 34020, 34960, 38514, 46363, 47684, 58519, 60547, 66889, 68157, 82805, 89493, 1849, 17420, 20127, 22149, 23155, 29145, 32398, 34020, 34960, 38514, 46363, 47684, 58519, 60547, 66889, 68157, 82805, 89493, 1849, 17420, 20127, 22149, 23155, 29145, 32398, 34020, 34960, 38514, 46363, 47684, 58519, 60547, 66889, 68157, 82805, 89493, 1849, 17420, 20127, 22149, 23155, 29145, 32398, 34020, 34960, 38514]\n",
      "1849 Salome UreÃƒÂ±a Elementary School\n",
      "17420 Salome UreÃƒÂ±a Elementary School\n",
      "20127 Salome UreÃƒÂ±a Elementary School\n",
      "22149 Salome UreÃƒÂ±a Elementary School\n",
      "23155 Salome UreÃƒÂ±a Elementary School\n",
      "60547 Salome UreÃƒÂ±a Elementary School\n",
      "66889 Salome UreÃƒÂ±a Elementary School\n",
      "68157 Salome UreÃƒÂ±a Elementary School\n",
      "82805 Salome UreÃƒÂ±a Elementary School\n",
      "89493 Salome UreÃƒÂ±a Elementary School\n",
      "Total with issue: 324\n",
      "[]\n",
      "Total with issue: 0\n",
      "[]\n",
      "Total with issue: 0\n"
     ]
    }
   ],
   "source": [
    "check_extra_specs('county')\n",
    "check_extra_specs('district')\n",
    "check_extra_specs('school')\n",
    "check_extra_specs('certificate')\n",
    "check_extra_specs('highly_qualified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3a2a6dc-c176-4e98-9387-6377ef79db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['county'] = df['county'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['district'] = df['district'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['school'] = df['school'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['certificate'] = df['certificate'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['highly_qualified'] = df['highly_qualified'].str.replace(r'[^A-Za-z\\s]', '', regex=True)\n",
    "df['primary_job'] = df['primary_job'].str.replace(r'[^A-Za-z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0108cb2a-70ba-4ea6-986e-80dcbd2ef210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Total with issue: 0\n",
      "[]\n",
      "Total with issue: 0\n",
      "[]\n",
      "Total with issue: 0\n",
      "[]\n",
      "Total with issue: 0\n",
      "[]\n",
      "Total with issue: 0\n",
      "[]\n",
      "Total with issue: 0\n"
     ]
    }
   ],
   "source": [
    "check_extra_specs('primary_job')\n",
    "check_extra_specs('county')\n",
    "check_extra_specs('district')\n",
    "check_extra_specs('school')\n",
    "check_extra_specs('certificate')\n",
    "check_extra_specs('highly_qualified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e9dce04-b710-4aa6-9047-9a5fa4956c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99954 entries, 0 to 100004\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   99954 non-null  int32  \n",
      " 1   last_name            99954 non-null  object \n",
      " 2   first_name           99954 non-null  object \n",
      " 3   county               99954 non-null  object \n",
      " 4   district             99954 non-null  object \n",
      " 5   school               99954 non-null  object \n",
      " 6   primary_job          99954 non-null  object \n",
      " 7   fte                  99954 non-null  float32\n",
      " 8   salary               99954 non-null  int32  \n",
      " 9   certificate          99954 non-null  object \n",
      " 10  subcategory          99954 non-null  object \n",
      " 11  teaching_route       99954 non-null  object \n",
      " 12  highly_qualified     99954 non-null  object \n",
      " 13  experience_district  99954 non-null  int8   \n",
      " 14  experience_nj        99954 non-null  int8   \n",
      " 15  experience_total     99954 non-null  int8   \n",
      "dtypes: float32(1), int32(2), int8(3), object(10)\n",
      "memory usage: 11.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99954, 16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908cf6bb",
   "metadata": {},
   "source": [
    "## Dropping Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bad33d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6f9562f-1eca-4f10-965b-abc051aa0777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99954 entries, 0 to 100004\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   99954 non-null  int32  \n",
      " 1   last_name            99954 non-null  object \n",
      " 2   first_name           99954 non-null  object \n",
      " 3   county               99954 non-null  object \n",
      " 4   district             99954 non-null  object \n",
      " 5   school               99954 non-null  object \n",
      " 6   primary_job          99954 non-null  object \n",
      " 7   fte                  99954 non-null  float32\n",
      " 8   salary               99954 non-null  int32  \n",
      " 9   certificate          99954 non-null  object \n",
      " 10  subcategory          99954 non-null  object \n",
      " 11  teaching_route       99954 non-null  object \n",
      " 12  highly_qualified     99954 non-null  object \n",
      " 13  experience_district  99954 non-null  int8   \n",
      " 14  experience_nj        99954 non-null  int8   \n",
      " 15  experience_total     99954 non-null  int8   \n",
      "dtypes: float32(1), int32(2), int8(3), object(10)\n",
      "memory usage: 11.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99954, 16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6af6de",
   "metadata": {},
   "source": [
    "## Saving Datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c6c91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05cbf6",
   "metadata": {},
   "source": [
    "## Connecting to SQL and Creating Database from Cleansed Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0aa0e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "mydb = sq.connect(host=\"localhost\",user=\"root\",passwd=\"042497AS\", buffered=True)\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d78318cb-1d54-4053-abba-4a01cfe2aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "mycursor.execute('USE nj_state_teachers_salaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9c02aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "mycursor.execute(\"CREATE TABLE IF NOT EXISTS nj_state_teachers_salaries.teachers_salaries_pset4 \\\n",
    "(id INT NOT NULL, last_name TEXT, first_name TEXT, county TEXT, district TEXT, \\\n",
    "school TEXT, primary_job TEXT, fte FLOAT, salary INT, certificate TEXT, \\\n",
    "subcategory TEXT, teaching_route TEXT, highly_qualified TEXT, experience_district INT, \\\n",
    "experience_nj INT, experience_total INT, PRIMARY KEY (id))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6ba0ed4-e7b3-4fee-a492-1464359904c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db875940-503f-47f9-b1da-864005c9ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"SET SESSION wait_timeout=28800\") \n",
    "mycursor.execute(\"SET SESSION interactive_timeout=28800\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "241c5661-9cc6-441e-8763-387e90ddd3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"\"\"\n",
    "    LOAD DATA INFILE '/usr/local/mysql/upload/cleaned_data.csv' \n",
    "    INTO TABLE nj_state_teachers_salaries.teachers_salaries_pset4\n",
    "    FIELDS TERMINATED BY ','\n",
    "    OPTIONALLY ENCLOSED BY '\"'  \n",
    "    ESCAPED BY '\\\\\\\\'\n",
    "    LINES TERMINATED BY '\\\\n'\n",
    "    IGNORE 1 ROWS;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "262fc1e9-46f9-46e4-a636-e9a726e1b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81271dfc",
   "metadata": {},
   "source": [
    "## Checking Proper SQL Table Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c84b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in teachers_salaries table : 99954\n"
     ]
    }
   ],
   "source": [
    "cmd = \"select count(*) from \\\n",
    "                 nj_state_teachers_salaries.teachers_salaries_pset4 \"\n",
    "mycursor.execute(cmd)\n",
    "count = mycursor.fetchone()[0]\n",
    "\n",
    "print(f\"Number of rows in teachers_salaries table : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9f8d503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in teachers_salaries table : 16\n"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"SELECT COUNT(*) \\\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS \\\n",
    "                WHERE table_schema = 'nj_state_teachers_salaries' \\\n",
    "                AND table_name = 'teachers_salaries_pset4'\"\"\"\n",
    "mycursor.execute(cmd)\n",
    "count = mycursor.fetchone()[0]\n",
    "print(f\"Number of columns in teachers_salaries table : {count}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c6647",
   "metadata": {},
   "source": [
    "## Creating Dataframe from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bcf04910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  last_name first_name     county                  district  \\\n",
      "0   5907  Velasquez       Carl  Hunterdon  South Hunterdon Regional   \n",
      "1  91649      Evans      James     Mercer              Hamilton Twp   \n",
      "2  33656      Davis     Amanda     Mercer  Hopewell Valley Regional   \n",
      "3  37479  Mcconnell     Robert     Mercer  Hopewell Valley Regional   \n",
      "4  63816    Francis     Elijah   Monmouth               Neptune Twp   \n",
      "\n",
      "                                school                    primary_job  fte  \\\n",
      "0               West Amwell Twp School  Elementary Kindergraten Grade  0.5   \n",
      "1             Hamilton Northnottingham    Elementary School Teacher K  0.8   \n",
      "2  Hopewell Valley Central High School     Health  Physical Education  0.8   \n",
      "3             Timberlane Middle School       Resource Program Inclass  1.0   \n",
      "4  Shark River Hills Elementary School                    Music Vocal  0.8   \n",
      "\n",
      "   salary           certificate subcategory teaching_route  \\\n",
      "0   74437  Standard certificate  Special ed    Traditional   \n",
      "1   67426                  CEAS  Special ed    Traditional   \n",
      "2   70399  Standard certificate  General ed    Traditional   \n",
      "3  110165                  CEAS  Special ed    Traditional   \n",
      "4  105773  Standard certificate  General ed      Alternate   \n",
      "\n",
      "                     highly_qualified  experience_district  experience_nj  \\\n",
      "0                Not highly qualified                    9              9   \n",
      "1  Doesnt need to be highly qualified                   18             18   \n",
      "2  Doesnt need to be highly qualified                   13              8   \n",
      "3  Doesnt need to be highly qualified                   19             31   \n",
      "4                Not highly qualified                   13             11   \n",
      "\n",
      "   experience_total  \n",
      "0                 9  \n",
      "1                18  \n",
      "2                23  \n",
      "3                35  \n",
      "4                31  \n",
      "        id last_name   first_name      county          district  \\\n",
      "772  76099    Taylor      Monique      Camden     Waterford Twp   \n",
      "773  13819  Robinson        Laura      Bergen     Fort Lee Boro   \n",
      "774  32639    Mclean       Steven  Burlington     Riverside Twp   \n",
      "775  87334     David     Jennifer       Essex  Essex Co Voctech   \n",
      "776  83195   Serrano  Christopher      Bergen      Oakland Boro   \n",
      "\n",
      "                          school                      primary_job  fte  \\\n",
      "772   Thomas Richards Elementary      Lang Artsliteracy Grades     0.8   \n",
      "773                   School No   Assistant Principal High School  0.8   \n",
      "774  Riverside Elementary School    Elementary Kindergraten Grade  0.8   \n",
      "775           West Caldwell Tech               Math Nonelementary  1.0   \n",
      "776         Valley Middle School      Elementary School Teacher K  1.0   \n",
      "\n",
      "     salary           certificate subcategory teaching_route  \\\n",
      "772  110102                  CEAS  Special ed      Alternate   \n",
      "773   66928                  CEAS  Special ed      Alternate   \n",
      "774   92725                  CEAS  General ed      Alternate   \n",
      "775   93221                  CEAS  General ed    Traditional   \n",
      "776   92030  Standard certificate  Special ed      Alternate   \n",
      "\n",
      "                       highly_qualified  experience_district  experience_nj  \\\n",
      "772                Not highly qualified                   37             33   \n",
      "773  Doesnt need to be highly qualified                    9              9   \n",
      "774  Doesnt need to be highly qualified                   18             18   \n",
      "775  Doesnt need to be highly qualified                   23             27   \n",
      "776                Not highly qualified                   11             17   \n",
      "\n",
      "     experience_total  \n",
      "772                39  \n",
      "773                 9  \n",
      "774                18  \n",
      "775                23  \n",
      "776                17  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(777, 16)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "dff = pd.read_csv ('sample.csv')\n",
    "print(dff.head(5))\n",
    "print(dff.tail(5))\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4500f520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in /opt/anaconda3/lib/python3.13/site-packages (7.16.6)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (5.10.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (24.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (2.19.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from nbconvert) (5.14.3)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.13/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from jupyter-core>=4.7->nbconvert) (4.3.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/lib/python3.13/site-packages (from nbclient>=0.5.0->nbconvert) (8.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /opt/anaconda3/lib/python3.13/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/lib/python3.13/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/lib/python3.13/site-packages (from nbformat>=5.7->nbconvert) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/anaconda3/lib/python3.13/site-packages (from nbformat>=5.7->nbconvert) (4.23.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.13/site-packages (from beautifulsoup4->nbconvert) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
